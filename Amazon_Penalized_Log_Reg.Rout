
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──
✔ broom        1.0.7     ✔ recipes      1.1.0
✔ dials        1.3.0     ✔ rsample      1.2.1
✔ dplyr        1.1.4     ✔ tibble       3.2.1
✔ ggplot2      3.5.1     ✔ tidyr        1.3.1
✔ infer        1.0.7     ✔ tune         1.2.1
✔ modeldata    1.4.0     ✔ workflows    1.1.4
✔ parsnip      1.2.1     ✔ workflowsets 1.1.0
✔ purrr        1.0.2     ✔ yardstick    1.3.1
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Use tidymodels_prefer() to resolve common conflicts.
> library(embed)
> library(doParallel)
Loading required package: foreach

Attaching package: ‘foreach’

The following objects are masked from ‘package:purrr’:

    accumulate, when

Loading required package: iterators
Loading required package: parallel
> library(vroom)

Attaching package: ‘vroom’

The following object is masked from ‘package:yardstick’:

    spec

The following object is masked from ‘package:scales’:

    col_factor

> 
> ## Penalized Logistic Regression ## 
> 
> # Read in data
> train_data <- vroom('train.csv')
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> test_data <- vroom('test.csv')
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> # Change ACTION to factors
> train_data <- train_data %>% 
+   mutate(ACTION = as.factor(ACTION))
> 
> # Create a recipe
> penalized_log_reg_recipe <- recipe(ACTION ~ ., data = train_data) %>% 
+   step_mutate_at(all_predictors(), fn = factor) %>% 
+   step_other(all_nominal_predictors(), threshold = .001, other = 'Other') %>% 
+   step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>% 
+   step_normalize(all_numeric_predictors())
> 
> # Create model
> penalized_log_reg_model <- logistic_reg(mixture = tune(),
+                                         penalty = tune()) %>% 
+   set_engine('glmnet')
> 
> # Create workflow
> penalized_log_reg_wf <- workflow() %>% 
+   add_recipe(penalized_log_reg_recipe) %>% 
+   add_model(penalized_log_reg_model)
> 
> # Grid of values to tune over
> tuning_grid <- grid_regular(penalty(),
+                             mixture(),
+                             levels = 5)
> 
> # Split data for CV
> folds <- vfold_cv(train_data, v = 10, repeats = 1)
> 
> # Set up parallel computing
> detectCores() # 8
[1] 40
> cl <- makePSOCKcluster(8)
> registerDoParallel(8)
> 
> # Run the CV
> cv_results <- penalized_log_reg_wf %>% 
+   tune_grid(resamples = folds,
+             grid = tuning_grid,
+             metrics = metric_set(roc_auc))
> 
> # Find best tuning params
> best_tuning_params <- cv_results %>% 
+   select_best(metric = 'roc_auc')
> 
> # Finalize workflow
> final_wf <- penalized_log_reg_wf %>% 
+   finalize_workflow(best_tuning_params) %>% 
+   fit(data = train_data)
> 
> # Predict and format for submission
> log_reg_preds <- predict(final_wf, 
+                          new_data = test_data,
+                          type = "prob") %>% 
+   mutate(id = row_number(), ACTION = .pred_1) %>% 
+   select(id, ACTION)
> 
> # End parallel computing
> stopCluster(cl)
> 
> # Write out the file
> vroom_write(x = log_reg_preds, file = "./Penalized_Log_Reg.csv", delim = ",")
> 
> # Score: 0.78337
> 
> proc.time()
   user  system elapsed 
192.035   3.734  56.007 
